{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "import random\n",
    "import sentencepiece as spm\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "from data import data_preparation\n",
    "from models import models_path\n",
    "from evaluation import scoring\n",
    "from training import lstm, rnn_attention\n",
    "from generation import generation_strategies\n",
    "from datafiles import datafiles_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data\n",
    "## Doesn't need to be run if you already have the datafiles and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://data.statmt.org/wmt16/translation-task/training-parallel-nc-v11.tgz\n",
      "Extracting news-commentary-v11.de-en.de\n",
      "Extracting news-commentary-v11.de-en.en\n"
     ]
    }
   ],
   "source": [
    "# Download the raw parallel news commentary archive from the wmt16 server\n",
    "# and save the english and german files\n",
    "# This might take about 30 seconds\n",
    "data_preparation.download_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle and split the datasets into train, dev and test subsets\n",
    "data_preparation.split_data(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A new currency was introduced and pegged to the US dollar at a one-to-one exchange rate',\n",
       "       \"Today's market fundamentalist creed fails to recognize that financial markets are inherently unstable\",\n",
       "       'Finally, Koreans must relearn the entrepreneurialism that built the chaebol, the family-owned industrial conglomerates that powered the economy’s development',\n",
       "       'In fact, the Spanish economy is a classic case of a defective growth pattern followed by a predictable, policy-assisted recovery that is driven (with a delay) mostly by the tradable sector',\n",
       "       'Nowhere is this better illustrated than in America’s current debate over illegal immigration',\n",
       "       'Across the región, Chávez’s influence was strong',\n",
       "       \"By foregoing prices in allocating healthcare, the Dutch have taken the economic incentives for extending life away from the country's physicians\",\n",
       "       'It is not', 'So who will step aside for whom remains unclear',\n",
       "       'Since the 1960s, there has been loose talk in Western Europe that Turkey might one day become a member of the European Community, now the EU'],\n",
       "      dtype='<U1227')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preparation.get_data(language=\"en\", split=\"train\")[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Eine neue Währung wurde eingeführt und mit einem festen Wechselkurs im Verhältnis 1:1 an den Dollar gekoppelt',\n",
       "       'Heutige Marktfundamentalisten verfehlen die Einsicht, das Finanzmärkte von sich aus instabil sind',\n",
       "       'Schließlich müssen die Koreaner jenen Unternehmergeist wiederfinden, der den Aufbau der Chaebol ermöglichte, jener in Familienbesitz stehender Unternehmensnetzwerke, die die wirtschaftliche Entwicklung des Landes vorantrieben',\n",
       "       ..., 'Dabei handelt es sich um sehr wichtige Fragen',\n",
       "       'Viele von ihnen haben Jobs, mit denen sie zusätzliche Kredite aufnehmen müssen, nur um sich über Wasser zu halten',\n",
       "       'Europa kann einfach nicht auf die Briten zählen, zumindest für eine Weile'],\n",
       "      dtype='<U1499')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preparation.get_data(language=\"de\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train one tokenizer (SentencePieceBPE) for the english and german training data splits\n",
    "# This might take about 20 seconds\n",
    "tokenizer_path = data_preparation.train_tokenizer(\n",
    "    data=np.concatenate(\n",
    "        [\n",
    "            data_preparation.get_data(language=\"en\", split=\"train\"),\n",
    "            data_preparation.get_data(language=\"de\", split=\"train\")\n",
    "        ]\n",
    "    ),\n",
    "    vocab_size=8_000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids_en_train = data_preparation.encode(language=\"en\", split=\"train\", tokenizer_path=tokenizer_path, add_bos=True, add_eos=True)\n",
    "token_ids_de_train = data_preparation.encode(language=\"de\", split=\"train\", tokenizer_path=tokenizer_path, add_bos=True, add_eos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A new currency was introduced and pegged to the US dollar at a one-to-one exchange rate',\n",
       " \"Today's market fundamentalist creed fails to recognize that financial markets are inherently unstable\",\n",
       " 'Finally, Koreans must relearn the entrepreneurialism that built the chaebol, the family-owned industrial conglomerates that powered the economy’s development']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preparation.decode(token_ids_en_train[:3], tokenizer_path=tokenizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = models_path / \"tokenizer\" / \"en_de_8000.model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a)\n",
    "Shuffle all tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids_de_test = data_preparation.encode(language=\"de\", split=\"test\", tokenizer_path=tokenizer_path, add_bos=False, add_eos=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids_de_test_shuffeled = copy.deepcopy(token_ids_de_test)\n",
    "for row in token_ids_de_test_shuffeled:\n",
    "    random.shuffle(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012694"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring.corpus_bleu_from_token_ids(references=token_ids_de_test, hypotheses=token_ids_de_test_shuffeled, tokenizer_path=tokenizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b)\n",
    "Replace tokens randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids_de_test = data_preparation.encode(language=\"de\", split=\"test\", tokenizer_path=tokenizer_path, add_bos=False, add_eos=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(str(tokenizer_path))\n",
    "token_ids_de_test_replaced = copy.deepcopy(token_ids_de_test)\n",
    "token_ids_de_test_replaced = [\n",
    "    [\n",
    "        random.randint(0, sp.vocab_size() - 1) if random.random() < 0.01 else x \n",
    "        for x in row\n",
    "    ]\n",
    "    for row in token_ids_de_test_replaced\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.975197"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring.corpus_bleu_from_token_ids(references=token_ids_de_test, hypotheses=token_ids_de_test_replaced, tokenizer_path=tokenizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_path = models_path / \"tokenizer\" / \"en_de_8000.model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation loss comparison of the models.\\\n",
    "Orange: RNN-Attention\\\n",
    "Blue: Unidirectional LSTM\\\n",
    "Green: Bidirectional LSTM\\\n",
    "<img src=\"images/comparison.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unidirectional LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training took 7h 15min and was done calling:\\\n",
    "```python ./training/train_lstm.py --model_name=\"encoder-decoder\" --num_epochs=20 --batch_size=32 --lr=1e-4 --embedding_dimension=512 --hidden_size=700 --bidirectional=False --val_steps=1000 --early_stopping=3```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/unidirectional_val_loss.png\" alt=\"drawing\" width=\"600\"/>\n",
    "<img src=\"images/unidirectional_train_batch_loss.png\" alt=\"drawing\" width=\"600\"/>\n",
    "<img src=\"images/unidirectional_train_avg_loss.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMEncoderDecoder(\n",
       "  (embedding): Embedding(8000, 512)\n",
       "  (encoder): LSTM(512, 700, batch_first=True)\n",
       "  (decoder): LSTM(512, 700, batch_first=True)\n",
       "  (final_linear): Linear(in_features=700, out_features=8000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model\n",
    "lstm_model = lstm.LSTMEncoderDecoder(\n",
    "    num_embeddings=8000,\n",
    "    embedding_dimension=512,\n",
    "    hidden_size=700,\n",
    "    bidirectional=False\n",
    ")\n",
    "state_dict = torch.load(models_path / \"encoder-decoder.pt\")\n",
    "lstm_model.load_state_dict(state_dict)\n",
    "lstm_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate translations for two samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.19it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2013 wird die Inflation in den USA und Großbritannien nicht mehr als 20 Prozent der Weltbevölkerung leben',\n",
       " 'Der Preissteigerungen ist nicht nur ein Problem, sondern auch für die Zukunft der Welt']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = generation_strategies.Generator(model=lstm_model)\n",
    "generator.generate_argmax_from_strings(\n",
    "    texts=[\n",
    "        \"A new currency was introduced and pegged to the US dollar at a one-to-one exchange rate\",\n",
    "        \"Today's market fundamentalist creed fails to recognize that financial markets are inherently unstable\"\n",
    "    ],\n",
    "    tokenizer_path=models_path / \"tokenizer\" / \"en_de_8000.model\",\n",
    "    max_generation_length=30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate BLEU score for the test set\\\n",
    "Predictions were generated using `python ./training/test_predictions.py --model_name=\"encoder-decoder\" --batch_size=64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictions\n",
    "with open(datafiles_path / \"predictions\" / f\"encoder-decoder_predictions_test_split.pkl\", \"rb\") as f:\n",
    "    prediction_tokens = pickle.load(f)\n",
    "token_ids_de_test = data_preparation.encode(language=\"de\", split=\"test\", tokenizer_path=tokenizer_path, add_bos=False, add_eos=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012927"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring.corpus_bleu_from_token_ids(references=token_ids_de_test, hypotheses=prediction_tokens, tokenizer_path=tokenizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training took 9h 15min was done calling:\\\n",
    "```python ./training/train_lstm.py --model_name=\"encoder-decoder-bidirectional\" --num_epochs=20 --batch_size=32 --lr=1e-4 --embedding_dimension=512 --hidden_size=700 --bidirectional=True --val_steps=1000 --early_stopping=3```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/bidirectional_val_loss.png\" alt=\"drawing\" width=\"600\"/>\n",
    "<img src=\"images/bidirectional_train_batch_loss.png\" alt=\"drawing\" width=\"600\"/>\n",
    "<img src=\"images/bidirectional_train_avg_loss.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMEncoderDecoder(\n",
       "  (embedding): Embedding(8000, 512)\n",
       "  (encoder): LSTM(512, 700, batch_first=True, bidirectional=True)\n",
       "  (hidden_projection): Linear(in_features=1400, out_features=700, bias=True)\n",
       "  (cell_projection): Linear(in_features=1400, out_features=700, bias=True)\n",
       "  (decoder): LSTM(512, 700, batch_first=True)\n",
       "  (final_linear): Linear(in_features=700, out_features=8000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model\n",
    "lstm_bidirectional_model = lstm.LSTMEncoderDecoder(\n",
    "    num_embeddings=8000,\n",
    "    embedding_dimension=512,\n",
    "    hidden_size=700,\n",
    "    bidirectional=True\n",
    ")\n",
    "state_dict = torch.load(models_path / \"encoder-decoder-bidirectional.pt\")\n",
    "lstm_bidirectional_model.load_state_dict(state_dict)\n",
    "lstm_bidirectional_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate translations for two samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['technungsrophetanehrtenteils der Markennung von Dollars und einer Verzerrung von Grundlagen, die die',\n",
       " 'Wieensammlungographiemandungseigenssenalen USA müssen']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = generation_strategies.Generator(model=lstm_bidirectional_model)\n",
    "generator.generate_argmax_from_strings(\n",
    "    texts=[\n",
    "        \"A new currency was introduced and pegged to the US dollar at a one-to-one exchange rate\",\n",
    "        \"Today's market fundamentalist creed fails to recognize that financial markets are inherently unstable\"\n",
    "    ],\n",
    "    tokenizer_path=models_path / \"tokenizer\" / \"en_de_8000.model\",\n",
    "    max_generation_length=30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate BLEU score for the test set\\\n",
    "Predictions were generated using `python ./training/test_predictions.py --model_name=\"encoder-decoder-bidirectional\" --batch_size=64`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictions\n",
    "with open(datafiles_path / \"predictions\" / f\"encoder-decoder-bidirectional_predictions_test_split.pkl\", \"rb\") as f:\n",
    "    prediction_tokens = pickle.load(f)\n",
    "token_ids_de_test = data_preparation.encode(language=\"de\", split=\"test\", tokenizer_path=tokenizer_path, add_bos=False, add_eos=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026404"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring.corpus_bleu_from_token_ids(references=token_ids_de_test, hypotheses=prediction_tokens, tokenizer_path=tokenizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNAttention\n",
    "(Bahdanau et al., 2014; https://arxiv.org/abs/1409.0473)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training was done by calling:\\\n",
    "```python ./training/train_rnn_attention.py --model_name=\"rnn-attention\" --num_epochs=10 --batch_size=4 --lr=1e-6 --teacher_forching_prob=0.5 --embedding_dimension=512 --hidden_size=512 --attention_dim=256 --maxout_size=256 --val_steps=8000 --early_stopping=3```\\\n",
    "Training was stopped after 2d 16h 10min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/attention_val_loss.png\" alt=\"drawing\" width=\"600\"/>\n",
    "<img src=\"images/attention_train_batch_loss.png\" alt=\"drawing\" width=\"600\"/>\n",
    "<img src=\"images/attention_train_avg_loss.png\" alt=\"drawing\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNAttention(\n",
       "  (encoder): RNNAttentionEncoder(\n",
       "    (embedding): Embedding(8000, 512)\n",
       "    (gru): GRU(512, 512, batch_first=True, bidirectional=True)\n",
       "    (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (decoder): RNNAttentionDecoder(\n",
       "    (attention): Alignment(\n",
       "      (hidden_projection): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (outputs_projection): Linear(in_features=1024, out_features=256, bias=True)\n",
       "      (energy_scale): Linear(in_features=256, out_features=1, bias=False)\n",
       "    )\n",
       "    (embedding): Embedding(8000, 512)\n",
       "    (gru): GRU(1536, 512, batch_first=True)\n",
       "    (linear_weighted_values): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (linear_hidden): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (linear_embeddings): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (linear_prediction): Linear(in_features=256, out_features=8000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model\n",
    "rnn_attention_encoder = rnn_attention.RNNAttentionEncoder(\n",
    "    num_embeddings=8000,\n",
    "    embedding_dimension=512,\n",
    "    hidden_size=512\n",
    ")\n",
    "rnn_attention_model = rnn_attention.RNNAttention(\n",
    "    encoder=rnn_attention_encoder,\n",
    "    decoder=rnn_attention.RNNAttentionDecoder(\n",
    "        embedding_layer=rnn_attention_encoder.embedding,\n",
    "        hidden_size=512,\n",
    "        attention_dim=256,\n",
    "        maxout_size=256\n",
    "    ),\n",
    "    random_seed=42\n",
    ")\n",
    "state_dict = torch.load(models_path / \"rnn-attention.pt\")\n",
    "rnn_attention_model.load_state_dict(state_dict)\n",
    "rnn_attention_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate translations for two samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 12.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Eine gilt Problem Obwohl und und und und und und und und und und und und und und und und und und und und und und und und und und',\n",
       " 'Die zweite der USA der USA der USA und der USA und der USA und der USA und der USA und der USA und der USA und der Welt –']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = generation_strategies.Generator(model=rnn_attention_model)\n",
    "generator.generate_argmax_from_strings(\n",
    "    texts=[\n",
    "        \"A new currency was introduced and pegged to the US dollar at a one-to-one exchange rate\",\n",
    "        \"Today's market fundamentalist creed fails to recognize that financial markets are inherently unstable\"\n",
    "    ],\n",
    "    tokenizer_path=models_path / \"tokenizer\" / \"en_de_8000.model\",\n",
    "    max_generation_length=30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate BLEU score for the test set\\\n",
    "Predictions were generated using `python ./training/test_predictions.py --model_name=\"rnn-attention\" --batch_size=8`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictions\n",
    "with open(datafiles_path / \"predictions\" / f\"rnn-attention_predictions_test_split.pkl\", \"rb\") as f:\n",
    "    prediction_tokens = pickle.load(f)\n",
    "token_ids_de_test = data_preparation.encode(language=\"de\", split=\"test\", tokenizer_path=tokenizer_path, add_bos=False, add_eos=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000771"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring.corpus_bleu_from_token_ids(references=token_ids_de_test, hypotheses=prediction_tokens, tokenizer_path=tokenizer_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3_11_std",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
